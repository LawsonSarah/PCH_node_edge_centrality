{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb2621e-b891-42e3-a565-79519a1274e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DELETE OUTPUTS AND RESTART KERNAL BEFORE RUNNING\n",
    "#RUN THIS FILE TO REPORUDCE RESULTS FROM \n",
    "#\"An application of node and edge nonlinear hypergrpah centrality to a protein complex hypernetwork.\" Lawson, S., Donovan, D., Lefevre,J. School of Mathematics and Physics, University of Queensland 2024 (unpublished). \n",
    "using JLD2 \n",
    "using SparseArrays\n",
    "using StatsBase\n",
    "using PyPlot\n",
    "using Plots\n",
    "using SimpleHypergraphs\n",
    "using Trapz\n",
    "using Graphs\n",
    "using LinearAlgebra\n",
    "using EvalMetrics\n",
    "using Combinatorics\n",
    "using DelimitedFiles\n",
    "\n",
    "#not sure if used:\n",
    "# using Statistics\n",
    "# using HypothesisTests\n",
    "# using Shuffle\n",
    "# using Metrics\n",
    "# using FileIO\n",
    "\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\sarit\\\\RA_code\\\\NSVC\" #file path for code folder\n",
    "output_path = \"$file_path\\\\Outputs\" #output folder for text files and plots\n",
    "include(\"$file_path\\\\data_processing_functions.jl\")\n",
    "include(\"$file_path\\\\mappings_initialization.jl\") \n",
    "include(\"$file_path\\\\compute_centrality_functions.jl\")\n",
    "include(\"$file_path\\\\analysis_functions.jl\") \n",
    "include(\"$file_path\\\\helper_functions.jl\") \n",
    "include(\"$file_path\\\\plot_functions.jl\") \n",
    "include(\"$file_path\\\\high_performance.jl\") \n",
    "\n",
    "#CHOOSE FUNCTION SETS - COMMENT OUT ALL FUNCTION SETS OTHER THAN ONE NEEDED  \n",
    "varying = \n",
    "#\"setA\"\n",
    "#\"setB_summary\"\n",
    "\"A_B_summary\"\n",
    "\n",
    "# \"1_1_c_k/c\"   #Full set of c, d=k/c for c,k in range 0.1:95  presaved as setA_1_1_c_kc_centralities-load below\n",
    "# \"setB_complete\" #   #Full set B centralitites for a,b,c,d presaved as setB_comb_0_1_195_95_centralities-load below\n",
    "\n",
    "#Algorithm parameters\n",
    "max_iterations = 800\n",
    "tolerance = 1e-6\n",
    "\n",
    "#percentage of essential proteins as edge essentiality criteria:\n",
    "\n",
    "e_percentage = 0.6  #at least 60% essential proteins in complex\n",
    "\n",
    "\n",
    "#6 percentage thresholds \n",
    "percent_threshold = [0.05, 0.10, 0.25, 0.50, 0.75, 1.0];\n",
    "\n",
    "\n",
    "#Process yeast complexes and essentiality data:\n",
    "dataset_name = \"yeast_protein\"\n",
    "name_title = \"Yeast Protein Complexes\"\n",
    "file = \"$file_path\\\\yeast_raw_data\\\\raw_complex_yeast.txt\"\n",
    "essential = \"$file_path\\\\yeast_raw_data\\\\essential_proteins_yeast.txt\"\n",
    "nonessential = \"$file_path\\\\yeast_raw_data\\\\nonessential_proteins_yeast.txt\"\n",
    "set_dict = yeast_complexes_set_dict(file) #create dictionary of complexes from raw file\n",
    "\n",
    "#Remove single member sets from set_dict:\n",
    "s = 0\n",
    "for i in keys(set_dict)\n",
    "    if length(set_dict[i]) == 1\n",
    "        delete!(set_dict, i)\n",
    "        s += 1\n",
    "    end\n",
    "end\n",
    "println(s, \" single member complexes removed\")\n",
    "\n",
    "#create text files to outputs folder and a dict with key:node name and value: node number. \n",
    "node_numbers_dict = data_processing(set_dict, dataset_name, output_path)\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "#CREATE HYPERGRAPH\n",
    "B, w, edgesx, edges_fromB, node_names_list, connected = read_hypergraph_data(\n",
    "    dataset_name,\n",
    "    output_path,\n",
    "    max_iterations = max_iterations,\n",
    "    tolerance = tolerance,\n",
    ");\n",
    "\n",
    "if !connected\n",
    "    #recaluclate for largest connected component:\n",
    "    #save original data:\n",
    "    orig_w = w\n",
    "    orig_B = B\n",
    "    orig_edges_fromB = edges_fromB\n",
    "    orig_set_dict = set_dict\n",
    "    orig_node_numbers_dict = node_numbers_dict\n",
    "    orig_node_names_list = node_names_list\n",
    "    orig_edges = edgesx\n",
    "    println(\"recalculating on largest connected component.\")\n",
    "    B, w, edgesx, edges_fromB, node_names_list, set_dict, dataset_name, node_numbers_dict =\n",
    "        max_component_recalculate(B, node_numbers_dict, set_dict, dataset_name)\n",
    "\n",
    "end\n",
    "\n",
    "#count nodes, edges and original sets\n",
    "no_nodes = size(B)[1]\n",
    "no_edges = size(B)[2]\n",
    "no_sets = Int(sum(w))\n",
    "\n",
    "println(\n",
    "    \"Hypergraph has $no_nodes nodes and $no_edges edges containing $no_sets set(s).\",\n",
    ")\n",
    "\n",
    "#dictionary containing key:node, value:list of edges node belongs to \n",
    "node_edges_dict = node_in_edges(node_numbers_dict, edges_fromB)\n",
    "\n",
    "#dictionary containing key:edge number value:original sets represented\n",
    "edge_number_dict = edge_numbers_dict(node_numbers_dict)\n",
    "\n",
    "#create dictionary of node and edge degrees\n",
    "ia = false #if ia = false then does not include max_edge, node adjacency, mean_deg in degree_centralities\n",
    "deg_centralities, edge_deg_centralities =\n",
    "    deg_centralities_dict(B, node_edges_dict, edges_fromB, edge_weights = w, inc_adj = ia)\n",
    "\n",
    "#create dictionary of nodes and edge essentiality status and print number of essential/nonessential nodes/edges\n",
    "node_ess_dict, unk, n_essent, n_non_essent =\n",
    "    node_class_dict(node_names_list, essential, nonessential, printlines = false)\n",
    "\n",
    "edge_ess_dict, e_essent, e_non_essent = edge_class_dict(\n",
    "    node_ess_dict,\n",
    "    edges_fromB,\n",
    "    node_names_list,\n",
    "    printlines = false,\n",
    "    per_ess = e_percentage,\n",
    ");\n",
    "\n",
    "println(\"Nodes essential: \", n_essent, \" Edges essential: \", e_essent)\n",
    "\n",
    "#################################################################################################################\n",
    "#Create or load centrality dictionary. \n",
    "\n",
    "\n",
    "centralities, ranked_nodes_dict, ranked_edges_dict, mappings =\n",
    "    initialization(varying); #centralitites based on 'varying' parameter\n",
    "\n",
    "#for efficiency, large centralitity dictionaries have been saved and can be preloaded.\n",
    "#centralities=load_object(\"setA_1_1_c_kc_centralities.jld2\") #centralitites for functions of the form P:(1,1,c,k/c) for c,k in range 0.1:95\n",
    "#centralities=load_object(\"setB_comb_0_1_195_95_centralities.jld2\") #centralitites for functions of the form P:(a,b,c,d) with a,c in {0,1,95,1/95} and b,d in {1,95,1/95}}\n",
    "\n",
    "#print summary of maximum true positives for centralities\n",
    "println(\"________________________________________________\")\n",
    "for cent_type in [\"x\", \"y\"]\n",
    "    for i in percent_threshold\n",
    "        max_true_pos(\n",
    "            cent_type,\n",
    "            centralities,\n",
    "            i,\n",
    "            n_essent,\n",
    "            e_essent,\n",
    "            n_non_essent,\n",
    "            e_non_essent,\n",
    "            node_ess_dict,\n",
    "            edge_ess_dict;\n",
    "            printlines = false,\n",
    "            reverse = true,\n",
    "        )\n",
    "    end\n",
    "\n",
    "    println(\"________________________________________________\")\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "#comment out the following if centrality dictionary is large\n",
    "# print summary of AUC and create plots\n",
    "\n",
    "for cent_type in [\"x\", \"y\"]\n",
    "    measures_dict = all_class_measures_plots(\n",
    "        cent_type,\n",
    "        centralities,\n",
    "        deg_centralities,\n",
    "        edge_deg_centralities,\n",
    "        n_essent,\n",
    "        n_non_essent,\n",
    "        node_ess_dict,\n",
    "        e_essent,\n",
    "        e_non_essent,\n",
    "        edge_ess_dict,\n",
    "        percent_threshold,\n",
    "        printlines = false,\n",
    "        varying = varying,\n",
    "    )\n",
    "end\n",
    "#######################################################################################################\n",
    "\n",
    "##print out max auc for node and edge high performers for setA_1_1_c_kc_centralities.jld2 and setB_comb_0_1_195_95_centralities.jld2\n",
    "\n",
    "#high_peform(n_essent, n_non_essent, e_essent, e_non_essent, node_ess_dict,edge_ess_dict)\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
